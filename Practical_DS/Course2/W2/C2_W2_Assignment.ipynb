{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a review classifier with BERT and Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In the previous lab you performed Feature Engineering on the raw dataset, preparing it for training the model. Now you will train a text classifier using a variant of BERT called [RoBERTa](https://arxiv.org/abs/1907.11692) - a Robustly Optimized BERT Pretraining Approach - within a PyTorch model ran as a SageMaker Training Job.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [1. Configure dataset, hyper-parameters and evaluation metrics](#c2w2-1.)\n",
    "  - [1.1. Configure dataset](#c2w2-1.1.)\n",
    "    - [Exercise 1](#c2w2-ex-1)\n",
    "    - [Exercise 2](#c2w2-ex-2)\n",
    "    - [Exercise 3](#c2w2-ex-3)\n",
    "  - [1.2. Configure model hyper-parameters](#c2w2-1.2.)\n",
    "  - [1.3. Setup evaluation metrics](#c2w2-1.3.)\n",
    "  - [1.4. Setup Debugger and Profiler](#c2w2-1.4.)\n",
    "- [2. Train model](#c2w2-2.)\n",
    "  - [2.1. Setup the RoBERTa and PyTorch script to run on SageMaker](#c2w2-2.1.)\n",
    "    - [Exercise 4](#c2w2-ex-4)\n",
    "    - [Exercise 5](#c2w2-ex-5)\n",
    "    - [Exercise 6](#c2w2-ex-6)\n",
    "  - [2.2. Analyze Debugger results](#c2w2-2.2.)\n",
    "  - [2.3. Download SageMaker debugger profiling report](#c2w2-2.3.)\n",
    "- [3. Deploy the model](#c2w2-3.)\n",
    "- [4. Test model](#c2w2-4.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review Amazon SageMaker \"Bring Your Own Script\" scheme:\n",
    "\n",
    "![](images/sagemaker_scriptmode.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will cover each part of the scheme. First, install and import the required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch==1.6.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2021.10.26 |       h06a4308_2         115 KB\n",
      "    conda-4.11.0               |   py37h06a4308_0        14.4 MB\n",
      "    cudatoolkit-10.2.89        |       hfd86e86_1       365.1 MB\n",
      "    ninja-1.10.2               |   py37hd09550d_3         1.5 MB\n",
      "    pytorch-1.6.0              |py3.7_cuda10.2.89_cudnn7.6.5_0       537.7 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       918.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.2.89-hfd86e86_1\n",
      "  ninja              pkgs/main/linux-64::ninja-1.10.2-py37hd09550d_3\n",
      "  pytorch            pytorch/linux-64::pytorch-1.6.0-py3.7_cuda10.2.89_cudnn7.6.5_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2021.10.~ --> pkgs/main::ca-certificates-2021.10.26-h06a4308_2\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  conda              conda-forge::conda-4.11.0-py37h89c186~ --> pkgs/main::conda-4.11.0-py37h06a4308_0\n",
      "\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# please ignore warning messages during the installation\n",
    "!pip install --disable-pip-version-check -q sagemaker==2.35.0\n",
    "!conda install -q -y pytorch==1.6.0 -c pytorch\n",
    "!pip install --disable-pip-version-check -q transformers==3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import botocore\n",
    "\n",
    "config = botocore.config.Config(user_agent_extra='dlai-pds/c2/w2')\n",
    "\n",
    "# low-level service client of the boto3 session\n",
    "sm = boto3.client(service_name='sagemaker', \n",
    "                  config=config)\n",
    "\n",
    "sm_runtime = boto3.client('sagemaker-runtime',\n",
    "                          config=config)\n",
    "\n",
    "sess = sagemaker.Session(sagemaker_client=sm,\n",
    "                         sagemaker_runtime_client=sm_runtime)\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sess.boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-1.'></a>\n",
    "# 1. Configure dataset, hyper-parameters and evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-1.1.'></a>\n",
    "### 1.1. Configure dataset\n",
    "\n",
    "You have already transformed and balanced the data into a format that the model expects. Let's copy this data to S3. You will be using training and validation datasets to train the model. Test dataset will be used for tuning later. Setup the paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_data_s3_uri = 's3://{}/data/sentiment-train/'.format(bucket)\n",
    "processed_validation_data_s3_uri = 's3://{}/data/sentiment-validation/'.format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the data to S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv to s3://sagemaker-us-east-1-739144860242/data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n",
      "upload: data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv to s3://sagemaker-us-east-1-739144860242/data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive ./data/sentiment-train $processed_train_data_s3_uri\n",
    "!aws s3 cp --recursive ./data/sentiment-validation $processed_validation_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the existence of those files in the S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-15 04:47:21    4894416 data/sentiment-train/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls --recursive $processed_train_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-15 04:47:22     276522 data/sentiment-validation/part-algo-1-womens_clothing_ecommerce_reviews.tsv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls --recursive $processed_validation_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to setup the input data channels, wrapping the S3 locations in a `TrainingInput` object to use with the SageMaker Training Job. This can be organized as a dictionary\n",
    "\n",
    "```python\n",
    "data_channels = {\n",
    "    'train': ..., # training data\n",
    "    'validation': ... # validation data\n",
    "}\n",
    "```\n",
    "\n",
    "where training and validation data are the Amazon SageMaker channels for S3 input data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-ex-1'></a>\n",
    "### Exercise 1\n",
    "\n",
    "Create a train data channel.\n",
    "\n",
    "**Instructions**: Pass the S3 input path for training data into the `sagemaker.inputs.TrainingInput` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_train_data = sagemaker.inputs.TrainingInput(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    s3_data=processed_train_data_s3_uri # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-ex-2'></a>\n",
    "### Exercise 2\n",
    "\n",
    "Create a validation data channel.\n",
    "\n",
    "**Instructions**: Pass the S3 input path for validation data into the `sagemaker.inputs.TrainingInput` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_validation_data = sagemaker.inputs.TrainingInput(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    s3_data=processed_validation_data_s3_uri # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-ex-3'></a>\n",
    "### Exercise 3\n",
    "\n",
    "Organize data channels defined above as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_channels = {\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    'train': s3_input_train_data, # Replace None\n",
    "    'validation': s3_input_validation_data # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-1.2.'></a>\n",
    "### 1.2. Configure model hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the Training Job parameters including the instance type, instance count, learning rate, batch size etc. For the purposes of this lab, you will use a relatively small instance type. Please refer to [this link](https://aws.amazon.com/sagemaker/pricing/) for additional instance types that may work for your use cases outside of this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length=128 # maximum number of input tokens passed to BERT model\n",
    "freeze_bert_layer=False # specifies the depth of training within the network\n",
    "epochs=3\n",
    "learning_rate=2e-5\n",
    "train_batch_size=256\n",
    "train_steps_per_epoch=50\n",
    "validation_batch_size=256\n",
    "validation_steps_per_epoch=50\n",
    "seed=42\n",
    "run_validation=True\n",
    "\n",
    "train_instance_count=1\n",
    "train_instance_type='ml.c5.9xlarge'\n",
    "train_volume_size=256\n",
    "input_mode='File'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of them will be passed into the PyTorch estimator in the hyperparameters argument. Let's setup the dictionary for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={\n",
    "    'max_seq_length': max_seq_length,\n",
    "    'freeze_bert_layer': freeze_bert_layer,\n",
    "    'epochs': epochs,\n",
    "    'learning_rate': learning_rate,\n",
    "    'train_batch_size': train_batch_size,\n",
    "    'train_steps_per_epoch': train_steps_per_epoch,\n",
    "    'validation_batch_size': validation_batch_size,\n",
    "    'validation_steps_per_epoch': validation_steps_per_epoch,    \n",
    "    'seed': seed,\n",
    "    'run_validation': run_validation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-1.3.'></a>\n",
    "### 1.3. Setup evaluation metrics\n",
    "\n",
    "Choose loss and accuracy as the evaluation metrics. The regular expressions `Regex` will capture the values of metrics that the algorithm will emit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "     {'Name': 'validation:loss', 'Regex': 'val_loss: ([0-9.]+)'},\n",
    "     {'Name': 'validation:accuracy', 'Regex': 'val_acc: ([0-9.]+)'},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, these sample log lines...\n",
    "```\n",
    "[step: 100] val_loss: 0.76 - val_acc: 70.92%\n",
    "```\n",
    "\n",
    "...will produce the following metrics in CloudWatch:\n",
    "\n",
    "`validation:loss` =  0.76\n",
    "\n",
    "`validation:accuracy` = 70.92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cloudwatch_validation_metrics.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-1.4.'></a>\n",
    "### 1.4. Setup Debugger and Profiler\n",
    "\n",
    "Amazon SageMaker Debugger can be used to profile machine learning models, helping to identify and fix training issues caused by hardware resource usage. Setting some parameters in the SageMaker estimator, without any change to the training code, you can enable the collection of infrastructure and model metrics such as: CPU and GPU, RAM and GPU RAM, data loading time, time spent in ML operators running on CPU and GPU, distributed training metrics and many more. In addition, you can visualize how much time is spent in different phases, such as preprocessing, training loop, and postprocessing. If needed, you can drill down on each training epoch, and even on each function in your training script.\n",
    "    \n",
    "Define Debugger Rules as described here:  https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import Rule, ProfilerRule, rule_configs\n",
    "from sagemaker.debugger import DebuggerHookConfig\n",
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DebuggerHookConfig` provides options to customize how debugging information is emitted and saved. `s3_output_path` argument value defines the location in Amazon S3 to store the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugger_hook_config = DebuggerHookConfig(\n",
    "    s3_output_path='s3://{}'.format(bucket),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ProfilerConfig` sets the configuration for collecting system and framework metrics of SageMaker Training Jobs. Parameter `system_monitor_interval_millis` sets the time interval to collect system metrics (in milliseconds). Parameter `framework_profile_params` is the object for framework metrics profiling. Here you will set its local path, the step at which to start profiling, `start_step`, and the number of steps to profile, `num_steps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500,\n",
    "    framework_profile_params=FrameworkProfile(local_path=\"/opt/ml/output/profiler/\", start_step=5, num_steps=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For monitoring and profiling the built-in rules you can use the `ProfilerReport`. It creates a profiling report and updates when the individual rules are triggered. If you trigger this `ProfilerReport` rule without any customized parameter as in the cell below, then the `ProfilerReport` rule triggers all of the built-in rules for monitoring and profiling with their default parameter values.\n",
    "\n",
    "The profiling report can be downloaded while the Training Job is running or after the job has finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules=[ProfilerRule.sagemaker(rule_configs.ProfilerReport())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-2.'></a>\n",
    "# 2. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-2.1.'></a>\n",
    "### 2.1. Setup the RoBERTa and PyTorch script to run on SageMaker\n",
    "You will prepare the PyTorch model to run as a SageMaker Training Job in a separate Python file, which will be called during the training. \n",
    "\n",
    "Here you will be using the pre-trained model `roberta-base`. The information about the available models can be found in the [Hugging Face website](https://huggingface.co/models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-ex-4'></a>\n",
    "### Exercise 4\n",
    "\n",
    "1. Open the file [src/train.py](src/train.py). Go through the comments to understand its content.\n",
    "2. Find and review the `configure_model()` function, which contains the RoBERTa model configuration. \n",
    "3. In the following function investigate given mapping `label2id` of a 0-indexed list of classes used by BERT \\[0, 1, 2\\] to the list of the sentiment values \\[-1, 0, 1\\]:\n",
    "\n",
    "```python\n",
    "    config = RobertaConfig.from_pretrained(\n",
    "        PRE_TRAINED_MODEL_NAME, \n",
    "        num_labels=len(classes),\n",
    "        id2label={\n",
    "            ...: ...,\n",
    "            ...: ...,\n",
    "            ...: ...,\n",
    "        },\n",
    "        label2id={\n",
    "            -1: 0,\n",
    "            0: 1,\n",
    "            1: 2,\n",
    "        }\n",
    "    )\n",
    "\n",
    "``` \n",
    "\n",
    "4. Update the function setting up the opposite mapping `id2label`: sentiment values \\[-1, 0, 1\\] to a 0-indexed list of classes used by BERT.\n",
    "\n",
    "5. Save the file [src/train.py](src/train.py) (with the menu command File -> Save Python File)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0afb8d6e784c45298848718ff1dded2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################\n",
      "Updated correctly!\n",
      "##################\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib\n",
    "sys.path.append('src/')\n",
    "\n",
    "import train\n",
    "\n",
    "# reload the module if it has been previously loaded\n",
    "if 'train' in sys.modules:\n",
    "    importlib.reload(train)\n",
    "\n",
    "# Ignore warnings below\n",
    "config = train.configure_model()\n",
    "\n",
    "label_0 = config.id2label[0]\n",
    "label_1 = config.id2label[1]\n",
    "label_2 = config.id2label[2]\n",
    "\n",
    "updated_correctly = False\n",
    "\n",
    "if label_0 != -1 or label_1 != 0 or label_2 != 1:\n",
    "    print('#######################################################################################')\n",
    "    print('Please check that the function \\'configure_model\\' in the file src/train.py is complete.')\n",
    "    print('########################################################################################')\n",
    "    raise Exception('Please check that the function \\'configure_model\\' in the file src/train.py is complete.')\n",
    "else:\n",
    "    print('##################')    \n",
    "    print('Updated correctly!')        \n",
    "    print('##################')        \n",
    "\n",
    "    updated_correctly = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the PyTorch estimator to train our model. For more information on the PyTorch estimator, see the documentation [here](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/sagemaker.pytorch.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch as PyTorchEstimator\n",
    "\n",
    "if updated_correctly:\n",
    "    estimator = PyTorchEstimator(\n",
    "        entry_point='train.py',\n",
    "        source_dir='src',\n",
    "        role=role,\n",
    "        instance_count=train_instance_count,\n",
    "        instance_type=train_instance_type,\n",
    "        volume_size=train_volume_size,\n",
    "        py_version='py3', # dynamically retrieves the correct training image (Python 3)\n",
    "        framework_version='1.6.0', # dynamically retrieves the correct training image (PyTorch)\n",
    "        hyperparameters=hyperparameters,\n",
    "        metric_definitions=metric_definitions,\n",
    "        input_mode=input_mode,\n",
    "        debugger_hook_config=debugger_hook_config,\n",
    "        profiler_config=profiler_config,\n",
    "        rules=rules\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-ex-5'></a>\n",
    "### Exercise 5\n",
    "\n",
    "Launch the SageMaker Training Job which will be fitting the model to the dataset.\n",
    "\n",
    "**Instructions**: Use the `estimator.fit` function, passing the configured train and validation inputs (data channels).\n",
    "\n",
    "```python\n",
    "estimator.fit(\n",
    "    inputs=..., # train and validation input\n",
    "    wait=False # do not wait for the job to complete before continuing\n",
    ")\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    inputs=data_channels, # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can refer to the last Training Job using the estimator function `latest_training_job`. Then the Training Job name can be found with the `name` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job name: pytorch-training-2021-12-15-05-15-42-641\n"
     ]
    }
   ],
   "source": [
    "training_job_name = estimator.latest_training_job.name\n",
    "\n",
    "print('Training Job name: {}'.format(training_job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also load the information about the Training Job using the function `describe()`. The result is in dictionary format. Let's check that it has the same Training Job name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job name: pytorch-training-2021-12-15-05-15-42-641\n"
     ]
    }
   ],
   "source": [
    "training_job_name = estimator.latest_training_job.describe()['TrainingJobName']\n",
    "\n",
    "print('Training Job name: {}'.format(training_job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-ex-6'></a>\n",
    "### Exercise 6\n",
    "\n",
    "Pull the Training Job status from the Training Job description.\n",
    "\n",
    "**Instructions**: Print the keys of the Training Job description dictionary, choose the one related to the primary status of the Training Job and print the value of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['TrainingJobName', 'TrainingJobArn', 'TrainingJobStatus', 'SecondaryStatus', 'HyperParameters', 'AlgorithmSpecification', 'RoleArn', 'InputDataConfig', 'OutputDataConfig', 'ResourceConfig', 'StoppingCondition', 'CreationTime', 'LastModifiedTime', 'SecondaryStatusTransitions', 'EnableNetworkIsolation', 'EnableInterContainerTrafficEncryption', 'EnableManagedSpotTraining', 'DebugHookConfig', 'ProfilerConfig', 'ProfilerRuleConfigurations', 'ProfilerRuleEvaluationStatuses', 'ProfilingStatus', 'ResponseMetadata'])\n"
     ]
    }
   ],
   "source": [
    "print(estimator.latest_training_job.describe().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Job status: InProgress\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "training_job_status_primary = estimator.latest_training_job.describe()['TrainingJobStatus'] # Replace None\n",
    "### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "print('Training Job status: {}'.format(training_job_status_primary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the Training Job in the console.\n",
    "\n",
    "**Instructions**: \n",
    "- open the link\n",
    "- notice that you are in the section `Amazon SageMaker` -> `Training jobs`\n",
    "- check the name of the Training Job, its status and other available information\n",
    "- review metrics in the `Monitor` section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/jobs/pytorch-training-2021-12-15-05-15-42-641\">Training Job</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/jobs/{}\">Training Job</a></b>'.format(region, training_job_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the Cloud Watch logs (after about 5 minutes).\n",
    "\n",
    "**Instructions**: \n",
    "- open the link\n",
    "- open the log stream with the name, which starts from the training job name\n",
    "- have a quick look at the log messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=/aws/sagemaker/TrainingJobs;prefix=pytorch-training-2021-12-15-05-15-42-641;streamFilter=typeLogStreamPrefix\">CloudWatch logs</a> after about 5 minutes</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/TrainingJobs;prefix={};streamFilter=typeLogStreamPrefix\">CloudWatch logs</a> after about 5 minutes</b>'.format(region, training_job_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-739144860242/pytorch-training-2021-12-15-05-15-42-641/?region=us-east-1&tab=overview\">S3 output data</a> after the Training Job has completed</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&tab=overview\">S3 output data</a> after the Training Job has completed</b>'.format(bucket, training_job_name, region)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the Training Job to complete.\n",
    "\n",
    "### _This cell will take approximately 30-40 minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "estimator.latest_training_job.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Wait until the ^^ Training Job ^^ completes above_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = estimator.training_job_analytics.dataframe()\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can query and plot the training metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.query(\"metric_name=='validation:accuracy'\").plot(x='timestamp', y='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-2.2.'></a>\n",
    "### 2.2. Analyze Debugger results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now explore the debugger output data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}?prefix={}/\">S3 debugger output data</a></b>'.format(\n",
    "            bucket, training_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-2.3.'></a>\n",
    "### 2.3. Download SageMaker debugger profiling report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download and review the debugger profiling report. Here is the path in the S3 bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler_report_s3_uri = \"s3://{}/{}/rule-output/ProfilerReport/profiler-output\".format(bucket, training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can list the report files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $profiler_report_s3_uri/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folder `profiler-reports` contains the built-in rule analysis components, stored in JSON and a Jupyter notebook. They are aggregated into the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive $profiler_report_s3_uri ./profiler_report/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can review the profiler report in the console.\n",
    "\n",
    "**Note**: Click `Trust HTML` in the profiler-report.html tab that opens (on top of the document)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"./profiler_report/profiler-report.html\">profiler report</a></b>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-3.'></a>\n",
    "# 3. Deploy the model\n",
    "Create a custom `SentimentPredictor` that encapsulates a JSONLines serializer and deserializer. To be passed into the `PyTorchModel` it needs to be wrapped as a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONLinesSerializer\n",
    "from sagemaker.deserializers import JSONLinesDeserializer\n",
    "\n",
    "class SentimentPredictor(Predictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super().__init__(endpoint_name, \n",
    "                         sagemaker_session=sagemaker_session, \n",
    "                         serializer=JSONLinesSerializer(),\n",
    "                         deserializer=JSONLinesDeserializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "timestamp = int(time.time())\n",
    "\n",
    "pytorch_model_name = '{}-{}-{}'.format(training_job_name, 'pt', timestamp)\n",
    "\n",
    "model = PyTorchModel(name=pytorch_model_name,\n",
    "                     model_data=estimator.model_data,\n",
    "                     predictor_cls=SentimentPredictor,\n",
    "                     entry_point='inference.py',\n",
    "                     source_dir='src',\n",
    "                     framework_version='1.6.0',\n",
    "                     py_version='py3',\n",
    "                     role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "pytorch_endpoint_name = '{}-{}-{}'.format(training_job_name, 'pt', timestamp)\n",
    "\n",
    "print(pytorch_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _This cell will take approximately 5-10 minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, \n",
    "                         instance_type='ml.m5.large', \n",
    "                         endpoint_name=pytorch_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the Endpoint in the AWS console.\n",
    "\n",
    "**Instructions**: \n",
    "- open the link\n",
    "- notice that you are in the section `Amazon SageMaker` -> `Endpoints`\n",
    "- check the name of the Endpoint, its status and other available information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST Endpoint</a></b>'.format(region, pytorch_endpoint_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c2w2-4.'></a>\n",
    "# 4. Test model\n",
    "Here, we will pass sample strings of text to the endpoint in order to see the sentiment. We give you one example of each, however, feel free to play around and change the strings yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    {\"features\": [\"I love this product!\"]},\n",
    "    {\"features\": [\"OK, but not great.\"]},\n",
    "    {\"features\": [\"This is not the right product.\"]},\n",
    "]\n",
    "\n",
    "predictor = SentimentPredictor(endpoint_name=pytorch_endpoint_name,\n",
    "                               sagemaker_session=sess)\n",
    "\n",
    "predicted_classes = predictor.predict(inputs)\n",
    "\n",
    "for predicted_class in predicted_classes:\n",
    "    print(\"Predicted class {} with probability {}\".format(predicted_class['predicted_label'], predicted_class['probability']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the notebook and train.py file into S3 bucket for grading purposes.\n",
    "\n",
    "**Note**: you may need to save the file before the upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./C2_W2_Assignment.ipynb to s3://sagemaker-us-east-1-739144860242/C2_W2_Assignment_Learner.ipynb\n",
      "upload: src/train.py to s3://sagemaker-us-east-1-739144860242/src/C2_W2_train_Learner.py\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./C2_W2_Assignment.ipynb s3://$bucket/C2_W2_Assignment_Learner.ipynb\n",
    "!aws s3 cp ./src/train.py s3://$bucket/src/C2_W2_train_Learner.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please go to the main lab window and click on `Submit` button (see the `Finish the lab` section of the instructions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
